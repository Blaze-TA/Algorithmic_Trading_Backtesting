{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n","<hr>"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# QuantBook Analysis Tool\n","# For more information see [https://www.quantconnect.com/docs/v2/our-platform/research/getting-started]\n","from datetime import datetime\n","from statsmodels.tsa.ar_model import AutoReg\n","from statsmodels.tsa.arima.model import ARIMA\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","qb = QuantBook()\n","\n","iShares_symbol = qb.add_equity('IVV').symbol\n","vanguard_symbol = qb.add_equity('VOO').symbol\n","\n","print(vanguard_symbol)\n","\n","start_date = datetime(2010, 9, 9)\n","end_date = datetime(2025, 10, 12)\n","history = qb.history([iShares_symbol, vanguard_symbol], start_date, end_date, Resolution.Daily)\n","\n","# print(history)\n","def get_rsquared(model_results, stock_daily_returns):\n","    fitted_values = model_results.fittedvalues\n","    actual_values = stock_daily_returns.iloc[1:]  # AutoReg drops first observation\n","\n","    # Calculate R²\n","    ss_res = np.sum((actual_values - fitted_values)**2)  # Sum of squared residuals\n","    ss_tot = np.sum((actual_values - actual_values.mean())**2)  # Total sum of squares\n","    r_squared = 1 - (ss_res / ss_tot)\n","\n","    return r_squared\n","closes = history['close'].copy()\n","print(closes)\n","closes.loc['IVV'] = (closes.loc['IVV'].values / closes.loc['IVV'][0]) * 100\n","closes.loc['VOO'] = (closes.loc['VOO'].values / closes.loc['VOO'][0]) * 100\n","# df.loc['IVV'] = df.loc['IVV'] / divisors['IVV']\n","# df.loc['VOO'] = df.loc['VOO'] / divisors['VOO']\n","print(closes)\n","\n","\n","daily_returns = closes.groupby(level='symbol').pct_change().dropna().copy()\n","daily_returns = daily_returns*100\n","\n","# print(daily_returns.loc['VOO'])\n","# print(daily_returns.loc['IVV'])\n","\n","# AR(1) model\n","iShare_model = AutoReg(daily_returns.loc['IVV'].values, lags = 1)\n","iShare_results = iShare_model.fit()\n","\n","rsquared = get_rsquared(iShare_results, daily_returns.loc['IVV'])\n","print(f\"R^2 = {rsquared}\")\n","iShare_results.summary()\n","\n","# Random walk with drift model\n","iShare_drift_model = ARIMA(daily_returns.loc['IVV'].values, order=(0,1,0), trend = 't')\n","iShare_drift_results = iShare_drift_model.fit()\n","\n","vanguard_drift_model = ARIMA(daily_returns.loc['VOO'].values, order=(0,1,0), trend = 't')\n","vanguard_drift_results = vanguard_drift_model.fit()\n","\n","print(iShare_drift_results.summary())\n","print(vanguard_drift_results.summary())\n","# Dicky-Fuller test\n","from statsmodels.tsa.stattools import adfuller\n","\n","IVV_result = adfuller(daily_returns.loc['IVV'].values, None, 'c', 'AIC')\n","VOO_result = adfuller(daily_returns.loc['VOO'].values, None, 'c', 'AIC')\n","\n","print(f\"DF IVV tao-stat = {IVV_result[0]}\")\n","print(f\"DF VOO tao-stat = {VOO_result[0]}\")\n","\n","# Large tao-stats for both tests > reject null that random walk w drift is non-stationary once differenced\n","# This implies H1: Yt is stationary with mean β1/(1-⍴)\n","# The first differences of each timeseries are stationary\n","# Cointegration\n","from statsmodels.tsa.stattools import coint\n","# print(len(daily_returns.loc['IVV'].values))\n","# print(len(daily_returns.loc['VOO'].values))\n","# print(daily_returns.loc['IVV'])\n","# print(daily_returns.loc['VOO'])\n","\n","IVV_hat = iShare_drift_results.fittedvalues.cumsum()  # reconstruct level from differenced fit\n","VOO_hat = vanguard_drift_results.fittedvalues.cumsum()\n","\n","cointegration_result = coint(daily_returns.loc['IVV'].values, daily_returns.loc['VOO'].values, 'c')\n","print(cointegration_result)\n","# Results state a cointegrated series is possbile\n","# Estimating the cointegrated series\n","import statsmodels.api as sm\n","from statsmodels.tsa.vector_ar.vecm import VECM\n","from statsmodels.tsa.vector_ar.vecm import coint_johansen\n","\n","# x_var = sm.add_constant(iShare_drift_model)\n","# cointegrated_model = sm.OLS(vanguard_drift_model, x_var).fit()\n","# cointegrated_model\n","# VECM()\n","\n","test_data = np.column_stack([daily_returns.loc['IVV'].values, daily_returns.loc['VOO'].values])\n","\n","coint_result = coint_johansen(test_data, det_order = 0, k_ar_diff = 1)\n","w1 = coint_result.evec[0, 0]\n","w2 = coint_result.evec[1, 0]\n","print(f\"w1 = {w1}, w2 = {w2}\")\n","\n","epsilon = w1 * daily_returns.loc['IVV'].values + w2 * daily_returns.loc['VOO'].values\n","\n","adf_result = adfuller(epsilon)\n","print(adf_result)\n","dates = daily_returns.index.get_level_values(1).unique()\n","\n","epsilon_mean = np.mean(epsilon)\n","epsilon_var = np.var(epsilon)\n","epsilon_std = np.sqrt(epsilon_var)\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(dates, epsilon, label='Residual ε_t')\n","plt.axhline(y=0, color='r', linestyle='--', linewidth=1, alpha=0.7, label='Zero line')\n","plt.axhline(y=epsilon_mean, color='r', linestyle='--', linewidth=1, alpha=0.7, label=f'Mean = {epsilon_mean:.4f}')\n","plt.axhline(y=epsilon_mean + 2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'+2σ = {epsilon_mean + 2*epsilon_std:.4f}')\n","plt.axhline(y=epsilon_mean - 2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'-2σ = {epsilon_mean - 2*epsilon_std:.4f}')\n","plt.title(f'Stationary Linear Combination: ε_t = {w1:.4f}*IVV + {w2:.4f}*VOO')\n","plt.xlabel('Date')\n","plt.ylabel('ε_t')\n","plt.xticks(rotation=45)\n","plt.grid(True, alpha=0.3)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","\n","# Applying the above application to different ETF pairs\n","def coint_graph(ticker_1, ticker_2, start_date):\n","    equity_1 = qb.add_equity(ticker_1).symbol\n","    equity_2 = qb.add_equity(ticker_2).symbol\n","    end_date = datetime(2025, 10, 12)\n","\n","    history = qb.history([equity_1, equity_2], start_date, end_date, Resolution.Daily)\n","    closes = history['close'].copy()\n","    closes.loc[ticker_1] = (closes.loc[ticker_1].values / closes.loc[ticker_1].iloc[0]) * 100\n","    closes.loc[ticker_2] = (closes.loc[ticker_2].values / closes.loc[ticker_2].iloc[0]) * 100\n","    test_data = np.column_stack([closes.loc[ticker_1].values, closes.loc[ticker_2].values])\n","\n","    coint_result = coint_johansen(test_data, det_order = 0, k_ar_diff = 1)\n","    w1 = coint_result.evec[0, 0]\n","    w2 = coint_result.evec[1, 0]\n","    epsilon = w1 * closes.loc[ticker_1].values + w2 * closes.loc[ticker_2].values\n","\n","    adf_result = adfuller(epsilon)\n","    dates = closes.index.get_level_values(1).unique()\n","    \n","    # Calculate mean and std\n","    epsilon_mean = np.mean(epsilon)\n","    epsilon_var = np.var(epsilon)\n","    epsilon_std = np.sqrt(epsilon_var)\n","\n","    print(f\"Dicky-Fuller results {adf_result}\")\n","    print(f\"Mean = {epsilon_mean}, Variance = {epsilon_var}, Std = {epsilon_std}\")\n","    \n","    plt.figure(figsize=(12, 6))\n","    plt.plot(dates, epsilon)\n","    plt.axhline(y=0, color='r', linestyle='--', linewidth=1, alpha=0.7, label='Zero line')\n","    plt.axhline(y=epsilon_mean, color='r', linestyle='--', linewidth=1, alpha=0.7, label=f'Mean = {epsilon_mean:.4f}')\n","    plt.axhline(y=epsilon_mean + 2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'+2σ = {epsilon_mean + 2*epsilon_std:.4f}')\n","    plt.axhline(y=epsilon_mean - 2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'-2σ = {epsilon_mean - 2*epsilon_std:.4f}')\n","    plt.title(f'Stationary Linear Combination: ε_t = {w1:.4f}*{ticker_1} + {w2:.4f}*{ticker_2}')\n","    plt.xlabel('Date')\n","    plt.ylabel('ε_t')\n","    plt.xticks(rotation=45)\n","    plt.grid(True, alpha=0.3)\n","    plt.legend()\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","coint_graph(\"QQQM\", \"QQQ\", datetime(2020, 10, 13))\n","coint_graph(\"VOO\", \"IVV\", datetime(2010, 9, 9))\n","coint_graph(\"IWM\", \"VTWO\", datetime(2010, 9, 24))\n","coint_graph(\"VTI\", \"IWV\", datetime(2001, 6, 1))\n","\n","coint_graph(\"IWM\", \"VTWO\", datetime(2022, 9, 24))\n","coint_graph(\"IWM\", \"VTWO\", datetime(2023, 9, 24))\n","coint_graph(\"IWM\", \"VTWO\", datetime(2024, 9, 24))\n","    # ETF_A = \"VTWO\"\n","    # ETF_B = \"IWV\"\n","from dateutil.relativedelta import relativedelta\n","\n","def iterative_coint_graph(ticker_1, ticker_2, start_date):\n","    equity_1 = qb.add_equity(ticker_1).symbol\n","    equity_2 = qb.add_equity(ticker_2).symbol\n","    end_date = start_date + relativedelta(years=1)\n","\n","    while end_date <= datetime.now():\n","        history = qb.history([equity_1, equity_2], start_date, end_date, Resolution.Daily)\n","        closes = history['close'].copy()\n","        closes.loc[ticker_1] = (closes.loc[ticker_1].values / closes.loc[ticker_1].iloc[0]) * 100\n","        closes.loc[ticker_2] = (closes.loc[ticker_2].values / closes.loc[ticker_2].iloc[0]) * 100\n","        test_data = np.column_stack([closes.loc[ticker_1].values, closes.loc[ticker_2].values])\n","\n","        coint_result = coint_johansen(test_data, det_order = 0, k_ar_diff = 1)\n","        w1 = coint_result.evec[0, 0]\n","        w2 = coint_result.evec[1, 0]\n","        epsilon = w1 * closes.loc[ticker_1].values + w2 * closes.loc[ticker_2].values\n","\n","        adf_result = adfuller(epsilon)\n","        dates = closes.index.get_level_values(1).unique()\n","        epsilon_var = np.var(epsilon)\n","        epsilon_std = np.sqrt(epsilon_var)\n","\n","        print(f\"Period: {start_date.date()} to {end_date.date()}\")\n","        print(f\"Dicky-Fuller results {adf_result}\")\n","        print(f\"Variance = {epsilon_var}, Std = {epsilon_std}\")\n","        print(f\"Expected value = {np.mean(epsilon)}\\n\")\n","        \n","        plt.figure(figsize=(12, 6))\n","        plt.plot(dates, epsilon)\n","        plt.axhline(y=0, color='r', linestyle='--', linewidth=1, alpha=0.7, label='Zero line')\n","        plt.axhline(y=np.mean(epsilon), color='r', linestyle='--', linewidth=1, alpha=0.7, label=f'Mean = {np.mean(epsilon):.4f}')\n","        plt.axhline(y=2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'+2σ = {2*epsilon_std:.4f}')\n","        plt.axhline(y=-2*epsilon_std, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'-2σ = {-2*epsilon_std:.4f}')\n","        plt.title(f'{ticker_1}/{ticker_2} ({start_date.date()} to {end_date.date()}): ε_t = {w1:.4f}*{ticker_1} + {w2:.4f}*{ticker_2}')\n","        plt.xlabel('Date')\n","        plt.ylabel('ε_t')\n","        plt.xticks(rotation=45)\n","        plt.grid(True, alpha=0.3)\n","        plt.legend()\n","        plt.tight_layout()\n","        plt.show()\n","\n","        # Move to next period\n","        start_date = end_date\n","        end_date = start_date + relativedelta(years=1)\n","\n","iterative_coint_graph(\"IWM\", \"VTWO\", datetime(2020, 9, 24))\n","\n","# =============== Rolling Window Cointegration Analysis ===============\n","def rolling_coint_analysis(ticker_1, ticker_2, full_start_date, full_end_date, window_years=2):\n","    \"\"\"\n","    Perform rolling window cointegration analysis.\n","    \n","    Parameters:\n","    - ticker_1, ticker_2: ETF tickers to analyze\n","    - full_start_date: earliest data to fetch\n","    - full_end_date: latest data to fetch\n","    - window_years: size of rolling window in years\n","    \"\"\"\n","    equity_1 = qb.add_equity(ticker_1).symbol\n","    equity_2 = qb.add_equity(ticker_2).symbol\n","    \n","    # Fetch all data once\n","    history = qb.history([equity_1, equity_2], full_start_date, full_end_date, Resolution.Daily)\n","    closes = history['close'].copy()\n","    closes.loc[ticker_1] = (closes.loc[ticker_1].values / closes.loc[ticker_1].iloc[0]) * 100\n","    closes.loc[ticker_2] = (closes.loc[ticker_2].values / closes.loc[ticker_2].iloc[0]) * 100\n","    \n","    # Initialize storage for results\n","    results = []\n","    \n","    current_start = full_start_date\n","    window_delta = relativedelta(years=window_years)\n","    \n","    while current_start + window_delta <= full_end_date:\n","        current_end = current_start + window_delta\n","        \n","        # Filter data for current window\n","        window_closes_1 = closes.loc[ticker_1]\n","        window_closes_2 = closes.loc[ticker_2]\n","        \n","        # Get dates in window\n","        dates_all = closes.index.get_level_values(1)\n","        mask = (dates_all >= current_start) & (dates_all <= current_end)\n","        \n","        if mask.sum() < 100:  # Skip if too few observations\n","            current_start = current_start + relativedelta(months=3)\n","            continue\n","            \n","        window_data = np.column_stack([\n","            closes.loc[ticker_1][mask].values,\n","            closes.loc[ticker_2][mask].values\n","        ])\n","        \n","        try:\n","            coint_result = coint_johansen(window_data, det_order=0, k_ar_diff=1)\n","            w1 = coint_result.evec[0, 0]\n","            w2 = coint_result.evec[1, 0]\n","            epsilon = w1 * window_data[:, 0] + w2 * window_data[:, 1]\n","            \n","            adf_result = adfuller(epsilon)\n","            \n","            results.append({\n","                'start': current_start,\n","                'end': current_end,\n","                'w1': w1,\n","                'w2': w2,\n","                'adf_stat': adf_result[0],\n","                'adf_pval': adf_result[1],\n","                'epsilon_mean': np.mean(epsilon),\n","                'epsilon_std': np.std(epsilon)\n","            })\n","            \n","        except Exception as e:\n","            print(f\"Error in window {current_start} to {current_end}: {e}\")\n","        \n","        # Move window forward by 3 months\n","        current_start = current_start + relativedelta(months=3)\n","    \n","    # Convert to DataFrame\n","    results_df = pd.DataFrame(results)\n","    \n","    # Plot results\n","    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n","    \n","    # Plot ADF statistic over time\n","    axes[0, 0].plot(results_df['start'], results_df['adf_stat'], marker='o')\n","    axes[0, 0].axhline(y=-2.86, color='r', linestyle='--', label='5% critical value')\n","    axes[0, 0].set_title('ADF Statistic Over Time')\n","    axes[0, 0].set_xlabel('Window Start Date')\n","    axes[0, 0].set_ylabel('ADF Statistic')\n","    axes[0, 0].legend()\n","    axes[0, 0].grid(True, alpha=0.3)\n","    \n","    # Plot hedge ratios over time\n","    axes[0, 1].plot(results_df['start'], results_df['w1'], marker='o', label=f'{ticker_1} weight')\n","    axes[0, 1].plot(results_df['start'], results_df['w2'], marker='o', label=f'{ticker_2} weight')\n","    axes[0, 1].set_title('Cointegration Weights Over Time')\n","    axes[0, 1].set_xlabel('Window Start Date')\n","    axes[0, 1].set_ylabel('Weight')\n","    axes[0, 1].legend()\n","    axes[0, 1].grid(True, alpha=0.3)\n","    \n","    # Plot epsilon std over time\n","    axes[1, 0].plot(results_df['start'], results_df['epsilon_std'], marker='o', color='green')\n","    axes[1, 0].set_title('Spread Volatility Over Time')\n","    axes[1, 0].set_xlabel('Window Start Date')\n","    axes[1, 0].set_ylabel('Std Dev of ε')\n","    axes[1, 0].grid(True, alpha=0.3)\n","    \n","    # Plot p-values over time\n","    axes[1, 1].plot(results_df['start'], results_df['adf_pval'], marker='o', color='purple')\n","    axes[1, 1].axhline(y=0.05, color='r', linestyle='--', label='5% significance')\n","    axes[1, 1].set_title('ADF Test P-values Over Time')\n","    axes[1, 1].set_xlabel('Window Start Date')\n","    axes[1, 1].set_ylabel('P-value')\n","    axes[1, 1].legend()\n","    axes[1, 1].grid(True, alpha=0.3)\n","    \n","    plt.tight_layout()\n","    plt.show()\n","    \n","    return results_df\n","\n","# Example usage\n","# rolling_results = rolling_coint_analysis(\"VTI\", \"IWV\", datetime(2010, 1, 1), datetime(2025, 10, 12), window_years=2)\n","\n","# =============== Copula-based Pairs Trading ===============\n","from scipy import stats\n","from copulas.bivariate import Gumbel, Clayton, Frank\n","import scipy.stats as stats\n","\n","\"\"\"Formation Period (first 12 months)\"\"\"\n","# Define the pair\n","ETF_A = \"VTI\"\n","ETF_B = \"IWV\"\n","\n","equity_A = qb.add_equity(ETF_A).symbol\n","equity_B = qb.add_equity(ETF_B).symbol\n","\n","# Formation period: 12 months for parameter estimation\n","formation_start = datetime(2023, 1, 1)\n","formation_end = datetime(2023, 12, 31)\n","\n","history_formation = qb.history([equity_A, equity_B], formation_start, formation_end, Resolution.Daily)\n","closes_formation = history_formation['close'].copy()\n","\n","# Calculate daily returns (percentage)\n","returns_A = closes_formation.loc[ETF_A].pct_change().dropna() * 100\n","returns_B = closes_formation.loc[ETF_B].pct_change().dropna() * 100\n","\n","# Ensure alignment\n","aligned_returns = pd.concat([returns_A.rename('A'), returns_B.rename('B')], axis=1, join='inner').dropna()\n","returns_A_aligned = aligned_returns['A'].values\n","returns_B_aligned = aligned_returns['B'].values\n","\n","# -------------------------\n","# 1) Fit marginal distributions (Student's t)\n","# -------------------------\n","IWV_df, IWV_loc, IWV_scale = stats.t.fit(returns_A_aligned)\n","VTI_df, VTI_loc, VTI_scale = stats.t.fit(returns_B_aligned)\n","\n","print(f\"{ETF_A} t-distribution parameters: df={IWV_df:.2f}, loc={IWV_loc:.4f}, scale={IWV_scale:.4f}\")\n","print(f\"{ETF_B} t-distribution parameters: df={VTI_df:.2f}, loc={VTI_loc:.4f}, scale={VTI_scale:.4f}\")\n","\n","# -------------------------\n","# 2) Transform to uniform marginals\n","# -------------------------\n","u = stats.t.cdf(returns_A_aligned, IWV_df, loc=IWV_loc, scale=IWV_scale)\n","v = stats.t.cdf(returns_B_aligned, VTI_df, loc=VTI_loc, scale=VTI_scale)\n","uv = np.column_stack([u, v])\n","\n","# -------------------------\n","# 3) Fit copula (Gumbel in this case)\n","# -------------------------\n","fitted_copula = Gumbel()\n","fitted_copula.fit(uv)\n","\n","print(f\"Fitted Gumbel copula with theta = {fitted_copula.theta:.4f}\")\n","\n","# -------------------------\n","# 4) Optionally compare multiple copulas\n","# -------------------------\n","    # copula_candidates = {\n","    #     'clayton': Clayton(),\n","    #     'frank': Frank(),\n","    #     'gumbel': Gumbel()\n","    # }\n","\n","    # copula_lls = {}\n","    # for name, cop in copula_candidates.items():\n","    #     try:\n","    #         cop.fit(uv)                      # fit method for 'copulas' library\n","    #         # compute log-likelihood: sum log pdf of joint copula density at uv\n","    #         ll = np.sum(np.log(cop.probability_density(uv) + 1e-15))\n","    #         copula_lls[name] = {'copula': cop, 'll': ll}\n","    #         print(f\"{name} log-likelihood value = {ll:.2f}\")\n","    #     except Exception as e:\n","    #         copula_lls[name] = {'copula': None, 'll': -np.inf}\n","    #         print(f\"{name} fit failed: {e}\")\n","\n","    # # -------------------------\n","    # # 5) Select best copula by log-likelihood\n","    # # -------------------------\n","    # best_copula_name = max(copula_lls.items(), key=lambda kv: kv[1]['ll'])[0]\n","    # best_copula = copula_lls[best_copula_name]['copula']\n","    # print(\"Best copula:\", best_copula_name)\n","\n","    # fitted_copula = Gumbel()\n","    # fitted_copula.fit(uv)\n","\n","\"\"\"Trading Period (current 12 months)\"\"\"\n","# (1) Calcualte the daily returns of the ETFs during the day\n","    # -> \n","    # new_IWV_returns = [0.1]\n","    # new_VTI_returns = [1.11]\n","\n","# (2) Calculate MIt X given Y and MIt Y given X\n","    # ->\n","    # u_new = stats.t.cdf(new_IWV_returns, IWV_df, loc=IWV_loc, scale=IWV_scale)\n","    # v_new = stats.t.cdf(new_VTI_returns, VTI_df, loc=VTI_loc, scale=VTI_scale)\n","    # uv_new = np.column_stack([u_new, v_new])\n","\n","    # # # Compute partial derivatives using the built-in method\n","    # partials_1 = fitted_copula.partial_derivative(uv_new)\n","    # uv_swapped = uv[:, [1, 0]]\n","    # partials_2 = fitted_copula.partial_derivative(uv_swapped)\n","\n","    # FlagX_t = fitted_copula.partial_derivative(uv_new)            # MI(Y|X)\n","    # uv_swapped = uv_new[:, [1, 0]]\n","    # FlagY_t = fitted_copula.partial_derivative(uv_swapped)    # MI(X|Y)\n","\n","    # # FlagX += FlagX_t[t] - 0.5  # for day t\n","    # # FlagY += FlagY_t[t] - 0.5\n","# (3) Use these signals to decided on trading or not\n","    # ->\n","    # D = 2, S = 0.6\n","    # When FlagX reaches D, we short-sell stock X and buy stock Y in equal amounts.\n","    # When FlagX reaches -D, we short-sell stock Y and buy stock X in equal amounts.\n","    # When FlagY reaches D, we short-sell stock Y and buy stock X in equal amounts.\n","    # When FlagY reaches -D, we short-sell stock X and buy stock Y in equal amounts.\n","\n","    # If trades are opened based on FlagX, then they are closed if FlagX returns to zero or\n","    # reaches stop-loss position S or -S. If they are opened based on FlagY, then they are closed if\n","    # FlagY returns to zero or reaches stop-loss position S or -S. After trades are closed, both FlagX\n","    # and FlagY are reset to zero, and all opening trades are closed at the end of the trading period\n","    # regardless of the values of FlagX and FlagY\n","new_IWV_returns = [0.222]\n","new_VTI_returns = [.11]\n","\n","u_new = stats.t.cdf(new_IWV_returns, IWV_df, loc=IWV_loc, scale=IWV_scale)\n","v_new = stats.t.cdf(new_VTI_returns, VTI_df, loc=VTI_loc, scale=VTI_scale)\n","uv_new = np.column_stack([u_new, v_new])\n","\n","copula_density = fitted_copula.probability_density(uv_new)\n","# print(copula_density)\n","theta = fitted_copula.theta\n","\n","\n","# # Compute partial derivatives using the built-in method\n","partials_1 = fitted_copula.partial_derivative(uv_new)\n","uv_swapped = uv_new[:, [1, 0]]\n","partials_2 = fitted_copula.partial_derivative(uv_swapped)\n","\n","# partials[:, 0] = ∂C(u,v)/∂u\n","# partials[:, 1] = ∂C(u,v)/∂v\n","# print(partials)\n","\n","print(\"Partial derivatives for first observation:\")\n","print(f\"∂C/∂u: {partials_1[0]}\")\n","print(f\"∂C/∂v: {partials_2[0]}\")\n","\n","# ---------- styling helpers ----------\n","def _nice_ax(ax):\n","    ax.grid(True, alpha=0.25, linewidth=0.8)\n","    for side in (\"top\", \"right\"):\n","        ax.spines[side].set_visible(False)\n","\n","def _tight_show(fig):\n","    fig.tight_layout()\n","    plt.show()\n","\n","# ---------- core charts ----------\n","def plot_prices_indexed(s1, s2, label1, label2, title_suffix=\"\"):\n","    \"\"\"\n","    s1, s2: pandas Series indexed by dates (already indexed-to-100).\n","    This function auto-aligns by the intersection of their indexes.\n","    \"\"\"\n","    common_idx = s1.index.intersection(s2.index)\n","    s1a, s2a = s1.reindex(common_idx), s2.reindex(common_idx)\n","\n","    fig, ax = plt.subplots(figsize=(12, 6))\n","    ax.plot(s1a.index, s1a.values, label=f\"{label1} (indexed to 100)\")\n","    ax.plot(s2a.index, s2a.values, label=f\"{label2} (indexed to 100)\")\n","    ax.set_title(f\"{label1} vs {label2} — Price Levels Indexed to 100 at Start{title_suffix}\")\n","    ax.set_xlabel(\"Date\")\n","    ax.set_ylabel(\"Indexed Price Level\")\n","    ax.legend(loc=\"best\")\n","    _nice_ax(ax); _tight_show(fig)\n","\n","def plot_stationary_combination(\n","    dates, epsilon, *, w1=None, w2=None, a_label=None, b_label=None,\n","    adf_tau=None, adf_p=None, bands=\"2sigma\", annotate=True\n","):\n","    mu = float(np.mean(epsilon))\n","    sig = float(np.std(epsilon, ddof=1))\n","    k = 2 if bands == \"2sigma\" else 3\n","\n","    title_bits = [\"Stationary Linear Combination: ε_t\"]\n","    if w1 is not None and w2 is not None and a_label and b_label:\n","        title_bits.append(f\" = {w1:.4f}·{a_label} + {w2:.4f}·{b_label}\")\n","    if adf_tau is not None and adf_p is not None:\n","        title_bits.append(f\"(ADF τ={adf_tau:.3f}, p={adf_p:.3f})\")\n","    title = \" — \".join(title_bits)\n","\n","    fig, ax = plt.subplots(figsize=(12, 6))\n","    ax.plot(dates, epsilon, label=\"Residual ε_t\", linewidth=1.5)\n","    ax.axhline(0.0, linestyle=\"--\", linewidth=1, alpha=0.7, color=\"r\", label=\"Zero line\")\n","    ax.axhline(mu, linestyle=\"--\", linewidth=1, alpha=0.7, color=\"r\", label=f\"Mean(ε_t) = {mu:.4f}\")\n","    ax.axhline(mu + k*sig, linestyle=\"--\", linewidth=1, alpha=0.7, color=\"orange\", label=f\"Upper band (+{k}σ) = {mu + k*sig:.4f}\")\n","    ax.axhline(mu - k*sig, linestyle=\"--\", linewidth=1, alpha=0.7, color=\"orange\", label=f\"Lower band (−{k}σ) = {mu - k*sig:.4f}\")\n","\n","    ax.set_title(title)\n","    ax.set_xlabel(\"Date\")\n","    ax.set_ylabel(\"Residual ε_t\")\n","\n","    if annotate:\n","        ax.text(\n","            0.01, 0.02,\n","            f\"μ={mu:.4f}, σ={sig:.4f}\",\n","            transform=ax.transAxes,\n","            fontsize=10,\n","            bbox=dict(facecolor=\"white\", edgecolor=\"none\", alpha=0.7)\n","        )\n","\n","    ax.legend(loc=\"best\")\n","    _nice_ax(ax); _tight_show(fig)\n","\n","# ---------- convenience wrapper ----------\n","def show_pair_price_and_epsilon(closes, ticker_a, ticker_b, epsilon, w1, w2, adf_result, eps_index):\n","    # price chart (uses each series' own index)\n","    sA = closes.loc[ticker_a]\n","    sB = closes.loc[ticker_b]\n","    plot_prices_indexed(sA, sB, ticker_a, ticker_b)\n","\n","    # residual chart (uses the exact index that matches epsilon)\n","    plot_stationary_combination(\n","        dates=eps_index,\n","        epsilon=epsilon,\n","        w1=w1, w2=w2,\n","        a_label=ticker_a, b_label=ticker_b,\n","        adf_tau=adf_result[0], adf_p=adf_result[1],\n","        bands=\"2sigma\", annotate=True\n","    )\n","\n","# ================= HOW TO CALL (IVV/VOO example) =================\n","# Build ε on ALIGNED returns so lengths match perfectly:\n","ret_ivv = daily_returns.loc['IVV']\n","ret_voo = daily_returns.loc['VOO']\n","aligned = pd.concat([ret_ivv.rename('IVV'), ret_voo.rename('VOO')], axis=1, join='inner').dropna()\n","\n","# If you computed w1, w2 from Johansen on (the same) returns, do:\n","epsilon = w1 * aligned['IVV'].values + w2 * aligned['VOO'].values\n","eps_index = aligned.index  # <-- correct dates for epsilon\n","\n","# Fixed: changed adf_eps to adf_result (using the variable computed earlier)\n","show_pair_price_and_epsilon(closes, 'IVV', 'VOO', epsilon, w1, w2, adf_result, eps_index)\n","\n","# ================= INSIDE coint_graph / iterative_coint_graph =================\n","# After you create 'closes' (indexed to 100) and compute w1, w2:\n","# ret_a = closes.loc[ticker_1].pct_change().dropna()\n","# ret_b = closes.loc[ticker_2].pct_change().dropna()\n","# aligned = pd.concat([ret_a.rename(ticker_1), ret_b.rename(ticker_2)], axis=1, join='inner').dropna()\n","# epsilon = w1*aligned[ticker_1].values + w2*aligned[ticker_2].values\n","# adf_eps = adfuller(epsilon)\n","# show_pair_price_and_epsilon(closes, ticker_1, ticker_2, epsilon, w1, w2, adf_eps, aligned.index)"]}],"metadata":{"kernelspec":{"display_name":"Foundation-Autogluon","language":"python","name":"foundation-autogluon"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":2}